{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a81459a-2373-45b2-baa5-072b05db29ae",
   "metadata": {},
   "source": [
    "# Performing Decision Tree Algorithm to Sort Witches and Wizards into Hogwarts Houses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9d8ac84a-7375-46a2-b59e-8f1561f43e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: unknown file attribute: i\n"
     ]
    }
   ],
   "source": [
    "![machine-learning-03.jpg](images/machine-learning-03.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58674756-29b6-4f2a-8bf4-0e37ebbc58fb",
   "metadata": {},
   "source": [
    "# 1. Introduction to the Magical Task\n",
    "\n",
    "In the world of magic, every young witch and wizard eagerly awaits the moment they set foot in the grand and ancient halls of Hogwarts School of Witchcraft and Wizardry. Their hearts brim with anticipation as they approach the Sorting Hat, that wise and venerable artifact, which will determine their house‚ÄîGryffindor, Hufflepuff, Ravenclaw, or Slytherin. üßô‚Äç‚ôÇÔ∏èüßô‚Äç‚ôÄÔ∏è\n",
    "\n",
    "But what if, dear reader, we could harness the power of Muggle technology to predict the Sorting Hat‚Äôs decisions? What if a spell of a different sort, known as the Decision Tree algorithm, could guide us in sorting our beloved characters into their rightful houses? Imagine a realm where the lines between magic and Muggle ingenuity blur, where the enchantment of Hogwarts meets the precision of mathematics! üè∞‚ú®\n",
    "\n",
    "In this enchanting tale, we shall embark on a journey to uncover how such a marvelous feat can be achieved. Our quest begins with a dataset‚Äîa collection of characters as diverse and magical as the pages of a wizard‚Äôs spellbook. Each character, from the brave Harry Potter to the cunning Draco Malfoy, carries with them a unique set of traits and characteristics. These traits, much like the intricate patterns of a spell, will be the key to our algorithm‚Äôs success.\n",
    "\n",
    "We shall delve into the world of data, treating each attribute with the care and attention of Hermione Granger poring over a particularly challenging potion recipe. From the form of their Patronus to their Quidditch position, every detail will play its part in this magical process.\n",
    "\n",
    "Our task is not merely a matter of data and numbers, but a celebration of the wonder and whimsy that makes the wizarding world so captivating. So, with wands at the ready and a sprinkle of Muggle knowledge, let us set forth on this magical adventure. Who knows what wonders we might uncover with a dash of magic and a touch of Muggle science? üé©ü™Ñ‚ú®"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd664a2-9411-4843-9716-3dc4a1ebd383",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b3a806-d8bd-465c-9d6f-769c739c041c",
   "metadata": {},
   "source": [
    "# 2. Gathering the Data\n",
    "\n",
    "In the hushed, candle-lit confines of the Hogwarts library, where the scent of ancient parchment mingles with the faint aroma of Madam Pince's restorative potions, we begin our quest for knowledge. üìöüïØÔ∏è Here, in this repository of magical wisdom, we gather the ingredients for our enchanted dataset‚Äîa veritable cauldron of information about our favorite witches and wizards.\n",
    "\n",
    "Our first task is to conjure a list of 50 magical individuals, each brimming with their own unique attributes and quirks. Much like the Sorting Hat, which perceives the innermost qualities of every student, we shall examine our characters through the lens of various magical features. Each entry in our dataset is a tapestry of details, woven together to tell the story of its subject. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a07d93-f196-4283-a548-79688d00501c",
   "metadata": {},
   "source": [
    "## 2.1 Dataset Features\n",
    "\n",
    "Let us explore these features, each as significant as a spell component in a well-crafted incantation:\n",
    "\n",
    "- **Name**: The given name of our witch or wizard, from the illustrious Harry Potter to the enigmatic Luna Lovegood. üåü\n",
    "- **Gender**: Whether they are a young wizard or witch, reflecting the diversity of Hogwarts.\n",
    "- **Age**: Their age at the time of sorting, for even the youngest students have their place in the castle's storied history.\n",
    "- **Origin**: The place they hail from, be it the rolling hills of England, the rugged highlands of Scotland, or the enchanting isles of Ireland. üèûÔ∏è\n",
    "- **Specialty**: Their area of magical expertise, such as Potions, Transfiguration, or Defense Against the Dark Arts, much like Professor Snape‚Äôs mastery of the subtle art of potion-making.\n",
    "- **House**: The revered house to which they belong‚ÄîGryffindor, Hufflepuff, Ravenclaw, or Slytherin‚Äîeach with its own rich traditions and values.\n",
    "- **Blood Status**: Whether they are Pure-blood, Half-blood, or Muggle-born, a detail that, while significant in the wizarding world, never diminishes their magical potential.\n",
    "- **Pet**: Their chosen magical companion, be it an owl, a cat, or a toad, reminiscent of Harry's loyal Hedwig or Hermione's clever Crookshanks. ü¶âüêà\n",
    "- **Wand Type**: The wood and core of their wand, the very tool of their magical prowess.\n",
    "- **Patronus**: The form their Patronus takes, a magical manifestation of their innermost self, like Harry's proud stag or Snape's ethereal doe. ü¶å\n",
    "- **Quidditch Position**: Their role in the beloved wizarding sport, whether Seeker, Chaser, Beater, or Keeper, or perhaps no position at all.\n",
    "- **Boggart**: The form their Boggart takes, a glimpse into their deepest fears.\n",
    "- **Favorite Class**: The subject they excel in or enjoy the most, akin to Hermione's love for Arithmancy or Neville's talent in Herbology.\n",
    "- **House Points**: Points they have contributed to their house, reflecting their achievements and misadventures alike.\n",
    "\n",
    "With this compendium of magical features, we craft our dataset with the precision of a spell-wright composing a new enchantment. Each character's details are meticulously recorded, ensuring that our data is as rich and detailed as the tapestry of Hogwarts itself. üßô‚Äç‚ôÇÔ∏èüè∞\n",
    "\n",
    "As we assemble this treasure trove of information, we prepare ourselves for the next step in our magical journey‚Äîtransforming these attributes into the foundations upon which our Decision Tree algorithm will cast its spell. Let us proceed, dear reader, for the magic is only just beginning! ‚ú®üåü"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689ff93e-ba70-41a5-935c-4f5fd5da2d90",
   "metadata": {},
   "source": [
    "## 2.2 The Python Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "afb10f61-17a5-48b0-bbe3-d2b0365e4ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully.\n",
      "Number of rows: 52\n",
      "Number of columns: 14\n",
      "\n",
      "Columns:\n",
      "Index(['name', 'gender', 'age', 'origin', 'specialty', 'house', 'blood_status',\n",
      "       'pet', 'wand_type', 'patronus', 'quidditch_position', 'boggart',\n",
      "       'favorite_class', 'house_points'],\n",
      "      dtype='object')\n",
      "\n",
      "First few rows:\n",
      "               name  gender  age   origin                      specialty  \\\n",
      "0      Harry Potter    Male   11  England  Defense Against the Dark Arts   \n",
      "1  Hermione Granger  Female   11  England                Transfiguration   \n",
      "2       Ron Weasley    Male   11  England                          Chess   \n",
      "3      Draco Malfoy    Male   11  England                        Potions   \n",
      "4     Luna Lovegood  Female   11  Ireland                      Creatures   \n",
      "\n",
      "        house blood_status  pet wand_type              patronus  \\\n",
      "0  Gryffindor   Half-blood  Owl     Holly                  Stag   \n",
      "1  Gryffindor  Muggle-born  Cat      Vine                 Otter   \n",
      "2  Gryffindor   Pure-blood  Rat       Ash  Jack Russell Terrier   \n",
      "3   Slytherin   Pure-blood  Owl  Hawthorn                   NaN   \n",
      "4   Ravenclaw   Half-blood  NaN       Fir                  Hare   \n",
      "\n",
      "  quidditch_position         boggart                 favorite_class  \\\n",
      "0             Seeker        Dementor  Defense Against the Dark Arts   \n",
      "1                NaN         Failure                     Arithmancy   \n",
      "2             Keeper          Spider                         Charms   \n",
      "3             Seeker  Lord Voldemort                        Potions   \n",
      "4                NaN      Her mother                      Creatures   \n",
      "\n",
      "   house_points  \n",
      "0         150.0  \n",
      "1         200.0  \n",
      "2          50.0  \n",
      "3         100.0  \n",
      "4         120.0  \n",
      "\n",
      "Summary statistics:\n",
      "             age  house_points\n",
      "count  52.000000     50.000000\n",
      "mean   14.942308    119.200000\n",
      "std     2.492447     54.129097\n",
      "min    11.000000     10.000000\n",
      "25%    13.250000     72.500000\n",
      "50%    16.000000    125.000000\n",
      "75%    17.000000    160.000000\n",
      "max    18.000000    200.000000\n",
      "\n",
      "First 10 names and houses:\n",
      "Name: Harry Potter, House: Gryffindor\n",
      "Name: Hermione Granger, House: Gryffindor\n",
      "Name: Ron Weasley, House: Gryffindor\n",
      "Name: Draco Malfoy, House: Slytherin\n",
      "Name: Luna Lovegood, House: Ravenclaw\n",
      "Name: Neville Longbottom, House: Gryffindor\n",
      "Name: Ginny Weasley, House: Gryffindor\n",
      "Name: Cedric Diggory, House: Hufflepuff\n",
      "Name: Cho Chang, House: Ravenclaw\n",
      "Name: Severus Snape, House: Slytherin\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "def gather_data(file_path):\n",
    "    \"\"\"\n",
    "    Function to load and explore the Hogwarts students dataset from a CSV file.\n",
    "    \n",
    "    Parameters:\n",
    "    - file_path (str): Path to the CSV file containing the dataset.\n",
    "    \n",
    "    Returns:\n",
    "    - df (DataFrame): Pandas DataFrame containing the loaded dataset.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the dataset into a pandas DataFrame\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Display basic information about the dataset\n",
    "        print(\"Dataset loaded successfully.\")\n",
    "        print(f\"Number of rows: {df.shape[0]}\")\n",
    "        print(f\"Number of columns: {df.shape[1]}\")\n",
    "        print(\"\\nColumns:\")\n",
    "        print(df.columns)\n",
    "        \n",
    "        # Display the first few rows of the dataset\n",
    "        print(\"\\nFirst few rows:\")\n",
    "        print(df.head())\n",
    "        \n",
    "        # Display summary statistics\n",
    "        print(\"\\nSummary statistics:\")\n",
    "        print(df.describe())\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{file_path}' was not found.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error: An unexpected error occurred - {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Path to the dataset file\n",
    "file_path = \"data/hogwarts-students.csv\"\n",
    "\n",
    "# Call the gather_data function to load and explore the dataset\n",
    "hogwarts_data = gather_data(file_path)\n",
    "\n",
    "# Example usage: Accessing specific columns\n",
    "if hogwarts_data is not None:\n",
    "    # Accessing 'name' and 'house' columns\n",
    "    names = hogwarts_data['name']\n",
    "    houses = hogwarts_data['house']\n",
    "    \n",
    "    # Displaying the first 10 names and their corresponding houses\n",
    "    print(\"\\nFirst 10 names and houses:\")\n",
    "    for name, house in zip(names[:10], houses[:10]):\n",
    "        print(f\"Name: {name}, House: {house}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13d969a-7eb2-4e14-a705-df0cc10f0c6a",
   "metadata": {},
   "source": [
    "## 2.3 Explanation:\n",
    "\n",
    "1. **Imports**: We import the pandas library (`import pandas as pd`) to work with DataFrames, which are used to handle structured data efficiently in Python.\n",
    "\n",
    "2. **gather_data Function**:\n",
    "   - **Purpose**: This function loads the dataset from the specified file path (`file_path`), prints basic information about the dataset (number of rows, columns, column names, first few rows, and summary statistics), and returns the loaded DataFrame (`df`).\n",
    "   - **Parameters**: `file_path` (str) - Path to the CSV file containing the dataset.\n",
    "   - **Returns**: `df` (DataFrame) - Pandas DataFrame containing the loaded dataset.\n",
    "\n",
    "3. **Error Handling**: The function includes error handling to manage scenarios where the file is not found (`FileNotFoundError`) or any other unexpected errors (`Exception`).\n",
    "\n",
    "4. **Main Execution**:\n",
    "   - Defines `file_path` as `\"data/hogwarts-students.csv\"`, assuming the dataset is located in a subfolder named `data`.\n",
    "   - Calls `gather_data(file_path)` to load and explore the dataset, assigning the result to `hogwarts_data`.\n",
    "\n",
    "5. **Example Usage**:\n",
    "   - Demonstrates accessing specific columns (`'name'` and `'house'`) from the loaded DataFrame (`hogwarts_data`).\n",
    "   - Prints the first 10 names and their corresponding houses as an example of data exploration.\n",
    "\n",
    "#### Notes:\n",
    "- Ensure the `pandas` library is installed (`pip install pandas`) before running the script.\n",
    "- Adjust `file_path` if the dataset file is located in a different directory.\n",
    "- This script provides a foundational approach to loading and initial exploration of the dataset, facilitating further data analysis or machine learning tasks as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf3286c-c290-4d90-a21f-56eb1b645e4a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b4faef-e800-4099-bf6c-309aca04836c",
   "metadata": {},
   "source": [
    "# 3. Preparing the Magical Ingredients (Data Preparation)\n",
    "\n",
    "In the heart of Hogwarts, where the walls whisper secrets of spells long past, we embark on the meticulous task of preparing our magical ingredients. Just as Professor Snape would demand precision in the art of potion-making, we must ensure that our data is impeccably prepared for the Decision Tree algorithm. üß™üìú‚ú®\n",
    "\n",
    "First, we must cleanse our dataset, ensuring every detail is as pristine as a freshly polished broomstick. No missing values or inconsistencies can be allowed, for even the slightest error could skew our magical predictions. Each entry, whether it be the courageous Harry Potter or the enigmatic Luna Lovegood, must be as accurate as the records in the Hogwarts library. üìö‚ú®\n",
    "\n",
    "**Data Cleaning**: Imagine the meticulous care of Professor McGonagall overseeing a Transfiguration lesson. We must remove any duplicates, fill in any gaps, and correct any errors. Each name, age, and specialty must be verified, ensuring that our dataset shines with the clarity of a well-cast Lumos spell. üí°\n",
    "\n",
    "**Feature Selection**: Next, we delve into the enchanted process of selecting the most relevant features. Not every detail may be necessary for our spell to work; we must choose wisely, much like selecting the right ingredients for a complex potion. Here, we focus on attributes that hold the key to unlocking the secrets of the Sorting Hat:\n",
    "\n",
    "- **Age**: The age at which the young witch or wizard arrives at Hogwarts.\n",
    "- **Origin**: The geographical background, which may influence certain traits.\n",
    "- **Specialty**: The magical prowess that defines their talents.\n",
    "- **Blood Status**: An aspect that, while contentious, can provide insight into house tendencies.\n",
    "- **Favorite Class**: The subject they excel in, hinting at their intellectual inclinations.\n",
    "- **House Points**: Reflecting their achievements and contributions to their house.\n",
    "\n",
    "**Encoding Categorical Variables**: Much like translating ancient runes, we must convert our categorical variables into a form that our Decision Tree can understand. For instance, turning the houses‚ÄîGryffindor, Hufflepuff, Ravenclaw, and Slytherin‚Äîinto numerical codes. This step is crucial, akin to a wizard learning the precise incantation for a spell. üßô‚Äç‚ôÄÔ∏èüî¢\n",
    "\n",
    "**Splitting the Dataset**: Now, with our data cleansed and encoded, we must divide it into two parts: the training set and the testing set. The training set is our practice ground, where the Decision Tree learns the intricate patterns of our data. The testing set, on the other hand, is where our spell‚Äôs true power is revealed, predicting the houses of unseen witches and wizards. This division is akin to practicing a charm repeatedly before demonstrating it in front of Professor Flitwick. üéìüîÆ\n",
    "\n",
    "As we complete this stage, our dataset is now a well-prepared potion, ready for the next step in our magical journey. The ingredients are measured, the cauldron is simmering, and the enchantment is ready to begin. With wands at the ready and hearts filled with anticipation, we move forward to cast our Decision Tree spell, predicting the houses of Hogwarts with Muggle precision and magical flair. üåü‚ú®"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4c63be-6bb1-470b-bcd8-09bbe28ca5ac",
   "metadata": {},
   "source": [
    "## 3.2 The Python Code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f63f0cf-ad70-48d8-8da6-769eb803ebd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully.\n",
      "Number of rows: 52\n",
      "Number of columns: 14\n",
      "\n",
      "Handling missing values...\n",
      "Encoding categorical variables...\n",
      "Splitting the dataset into training and testing sets...\n",
      "X_train shape: (41, 13), y_train shape: (41,)\n",
      "X_test shape: (11, 13), y_test shape: (11,)\n",
      "\n",
      "First few rows of X_train:\n",
      "    name  gender age  origin  specialty  blood_status  pet  wand_type  \\\n",
      "8      7       0  14       6          2             0    4         13   \n",
      "26    28       1  16       1          5             3    4         10   \n",
      "6     14       0  11       1          6             3    4         27   \n",
      "34    13       1  15       1         15             0    4          5   \n",
      "4     29       0  11       5          4             0    4         11   \n",
      "\n",
      "    patronus  quidditch_position  boggart  favorite_class house_points  \n",
      "8         13                   4        3               3        110.0  \n",
      "26         8                   4        3               5         90.0  \n",
      "6          5                   2       10               6        140.0  \n",
      "34         8                   4        3              13         70.0  \n",
      "4          4                   4        5               4        120.0  \n",
      "\n",
      "First few rows of y_train:\n",
      "8     4\n",
      "26    5\n",
      "6     2\n",
      "34    4\n",
      "4     4\n",
      "Name: house, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "def prepare_data(file_path):\n",
    "    \"\"\"\n",
    "    Function to prepare the Hogwarts students dataset for analysis and modeling.\n",
    "    \n",
    "    Parameters:\n",
    "    - file_path (str): Path to the CSV file containing the dataset.\n",
    "    \n",
    "    Returns:\n",
    "    - X_train (DataFrame): Training features DataFrame.\n",
    "    - X_test (DataFrame): Testing features DataFrame.\n",
    "    - y_train (Series): Training target Series.\n",
    "    - y_test (Series): Testing target Series.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the dataset into a pandas DataFrame\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Display basic information about the dataset\n",
    "        print(\"Dataset loaded successfully.\")\n",
    "        print(f\"Number of rows: {df.shape[0]}\")\n",
    "        print(f\"Number of columns: {df.shape[1]}\")\n",
    "        \n",
    "        # Handling missing values\n",
    "        print(\"\\nHandling missing values...\")\n",
    "        imputer = SimpleImputer(strategy='most_frequent')  # Impute with most frequent value\n",
    "        df_filled = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "        \n",
    "        # Encoding categorical variables\n",
    "        print(\"Encoding categorical variables...\")\n",
    "        label_encoder = LabelEncoder()\n",
    "        df_encoded = df_filled.copy()\n",
    "        for col in df.select_dtypes(include=['object']).columns:\n",
    "            df_encoded[col] = label_encoder.fit_transform(df_filled[col])\n",
    "        \n",
    "        # Splitting the dataset into training and testing sets\n",
    "        print(\"Splitting the dataset into training and testing sets...\")\n",
    "        X = df_encoded.drop('house', axis=1)  # Features (excluding the target 'house')\n",
    "        y = df_encoded['house']  # Target variable ('house')\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        \n",
    "        # Display the shapes of the training and testing sets\n",
    "        print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "        print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{file_path}' was not found.\")\n",
    "        return None, None, None, None\n",
    "    except Exception as e:\n",
    "        print(f\"Error: An unexpected error occurred - {str(e)}\")\n",
    "        return None, None, None, None\n",
    "\n",
    "# Path to the dataset file\n",
    "file_path = \"data/hogwarts-students.csv\"\n",
    "\n",
    "# Call the prepare_data function to prepare the dataset for analysis and modeling\n",
    "X_train, X_test, y_train, y_test = prepare_data(file_path)\n",
    "\n",
    "# Example usage: Displaying the first few rows of X_train and y_train\n",
    "if X_train is not None and y_train is not None:\n",
    "    print(\"\\nFirst few rows of X_train:\")\n",
    "    print(X_train.head())\n",
    "    print(\"\\nFirst few rows of y_train:\")\n",
    "    print(y_train.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31cbc58-7085-45de-b4b5-9cdb364e40d2",
   "metadata": {},
   "source": [
    "## 3.3 Explanation:\n",
    "\n",
    "1. **Imports**: We import necessary libraries including pandas (`import pandas as pd`), `train_test_split` from `sklearn.model_selection`, `LabelEncoder` from `sklearn.preprocessing`, and `SimpleImputer` from `sklearn.impute`.\n",
    "\n",
    "2. **prepare_data Function**:\n",
    "   - **Purpose**: This function prepares the Hogwarts students dataset for analysis and modeling by handling missing values, encoding categorical variables, and splitting the dataset into training and testing sets.\n",
    "   - **Parameters**: `file_path` (str) - Path to the CSV file containing the dataset.\n",
    "   - **Returns**: `X_train` (DataFrame), `X_test` (DataFrame), `y_train` (Series), `y_test` (Series) - Training and testing sets for features (`X_train`, `X_test`) and target (`y_train`, `y_test`).\n",
    "\n",
    "3. **Error Handling**: The function includes error handling to manage scenarios where the file is not found (`FileNotFoundError`) or any other unexpected errors (`Exception`).\n",
    "\n",
    "4. **Data Preparation Steps**:\n",
    "   - **Loading and Basic Information**: Loads the dataset into a pandas DataFrame (`df`) and prints basic information about its dimensions.\n",
    "   - **Handling Missing Values**: Uses `SimpleImputer` to fill missing values in the dataset with the most frequent value in each column.\n",
    "   - **Encoding Categorical Variables**: Uses `LabelEncoder` to transform categorical variables into numerical values, making them suitable for machine learning algorithms.\n",
    "   - **Splitting the Dataset**: Splits the dataset into training (`X_train`, `y_train`) and testing (`X_test`, `y_test`) sets using `train_test_split`, with a test size of 20% and a fixed random state for reproducibility.\n",
    "\n",
    "5. **Main Execution**:\n",
    "   - Defines `file_path` as `\"data/hogwarts-students.csv\"`, assuming the dataset is located in a subfolder named `data`.\n",
    "   - Calls `prepare_data(file_path)` to prepare the dataset for analysis and modeling, assigning the returned values (`X_train`, `X_test`, `y_train`, `y_test`) to variables for further use.\n",
    "\n",
    "6. **Example Usage**:\n",
    "   - Demonstrates accessing and displaying the first few rows of `X_train` (features) and `y_train` (target) after preparation.\n",
    "\n",
    "### Notes:\n",
    "\n",
    "- Ensure the `pandas` and `scikit-learn` libraries are installed (`pip install pandas scikit-learn`) before running the script.\n",
    "- Adjust `file_path` if the dataset file is located in a different directory.\n",
    "- This script provides a foundational approach to preparing data for machine learning tasks, ensuring data cleanliness and suitability for training predictive models. Adjustments can be made based on specific requirements or additional preprocessing steps needed for the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04df655-deeb-4c33-9316-c723568addc5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7b97f6-3f78-4394-b63f-661ee3998d97",
   "metadata": {},
   "source": [
    "# 4. Splitting the Dataset\n",
    "\n",
    "In the echoing halls of Hogwarts, where the portraits murmur and the suits of armor stand vigil, we proceed to the next crucial step of our magical journey: splitting the dataset. This task, as delicate as crafting a Philosopher's Stone, will ensure our Decision Tree spell learns and predicts with the wisdom of an ancient seer. üè∞‚ú®\n",
    "\n",
    "Imagine, if you will, Professor Flitwick guiding his students through a complex charm. Much like his careful tutelage, we must divide our dataset with precision. We begin by separating our collected data into two distinct sets: the **Training Set** and the **Testing Set**. These sets are the foundation upon which our magical prediction will be built.\n",
    "\n",
    "**The Training Set**: This set, dear reader, is where our Decision Tree algorithm will first spread its wings. Comprising 80% of our dataset, it includes the names and traits of characters we already know, like Hermione Granger‚Äôs keen intellect and Neville Longbottom‚Äôs brave heart. The algorithm will study these patterns, learning to associate specific attributes with the respective houses. It‚Äôs akin to a young witch or wizard practicing their wand movements before casting their first spell. üßô‚Äç‚ôÄÔ∏èüìò\n",
    "\n",
    "**The Testing Set**: The remaining 20% of our dataset forms the Testing Set, the proving ground for our spell. Here, the Decision Tree will face characters it has not encountered during training, much like a wizard facing an unknown challenge. The true measure of our spell‚Äôs accuracy will be revealed as it predicts the houses of these unseen students. This step is as thrilling as Harry‚Äôs first encounter with a dragon during the Triwizard Tournament. üêâ‚ú®\n",
    "\n",
    "To ensure our split is as precise as Professor Snape‚Äôs potion measurements, we use a method known in the Muggle world as **random sampling**. This technique ensures each character has an equal chance of being included in either set, preventing any bias that could cloud our results. It‚Äôs a bit like ensuring each house at Hogwarts has a fair chance during the House Cup‚Äîthough we know Gryffindor often has the edge! ü¶ÅüèÜ\n",
    "\n",
    "**Maintaining Balance**: As we split the dataset, we must also ensure that each house is fairly represented in both sets. This balance is crucial, for just as the four houses maintain harmony within Hogwarts, our balanced dataset ensures that the Decision Tree learns fairly about each house‚Äôs unique qualities. üè∞‚öñÔ∏è\n",
    "\n",
    "With our dataset now meticulously divided, we are ready to move to the next stage of our magical endeavor. The Training Set will impart its wisdom, and the Testing Set will reveal the accuracy of our predictions. The anticipation is as palpable as waiting for the Sorting Hat‚Äôs pronouncement on a new student‚Äôs first night at Hogwarts. üé©‚ú®\n",
    "\n",
    "Let us proceed with confidence, for the foundation is set, and the path to magical prediction lies before us. The Hogwarts houses await, ready to welcome their new members, as we cast our Decision Tree spell with Muggle ingenuity and wizarding wonder. üåüüßô‚Äç‚ôÇÔ∏èüßô‚Äç‚ôÄÔ∏è\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de93674a-e3d8-4209-8cdf-1b53d89b446f",
   "metadata": {},
   "source": [
    "## 4.1 Python Code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9fb9b966-d9d3-4859-9726-859bc2de9a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully.\n",
      "Number of rows: 52\n",
      "Number of columns: 14\n",
      "Splitting the dataset into training and testing sets...\n",
      "X_train shape: (41, 13), y_train shape: (41,)\n",
      "X_test shape: (11, 13), y_test shape: (11,)\n",
      "\n",
      "Shapes of the split datasets:\n",
      "X_train shape: (41, 13), y_train shape: (41,)\n",
      "X_test shape: (11, 13), y_test shape: (11,)\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_dataset(file_path, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Function to split the Hogwarts students dataset into training and testing sets.\n",
    "    \n",
    "    Parameters:\n",
    "    - file_path (str): Path to the CSV file containing the dataset.\n",
    "    - test_size (float): Proportion of the dataset to include in the test split (default is 0.2).\n",
    "    - random_state (int): Controls the shuffling applied to the data before applying the split (default is 42).\n",
    "    \n",
    "    Returns:\n",
    "    - X_train (DataFrame): Training features DataFrame.\n",
    "    - X_test (DataFrame): Testing features DataFrame.\n",
    "    - y_train (Series): Training target Series.\n",
    "    - y_test (Series): Testing target Series.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the dataset into a pandas DataFrame\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Display basic information about the dataset\n",
    "        print(\"Dataset loaded successfully.\")\n",
    "        print(f\"Number of rows: {df.shape[0]}\")\n",
    "        print(f\"Number of columns: {df.shape[1]}\")\n",
    "        \n",
    "        # Splitting the dataset into training and testing sets\n",
    "        print(\"Splitting the dataset into training and testing sets...\")\n",
    "        X = df.drop('house', axis=1)  # Features (excluding the target 'house')\n",
    "        y = df['house']  # Target variable ('house')\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "        \n",
    "        # Display the shapes of the training and testing sets\n",
    "        print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "        print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{file_path}' was not found.\")\n",
    "        return None, None, None, None\n",
    "    except Exception as e:\n",
    "        print(f\"Error: An unexpected error occurred - {str(e)}\")\n",
    "        return None, None, None, None\n",
    "\n",
    "# Path to the dataset file\n",
    "file_path = \"data/hogwarts-students.csv\"\n",
    "\n",
    "# Call the split_dataset function to split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = split_dataset(file_path)\n",
    "\n",
    "# Example usage: Displaying the shapes of X_train, X_test, y_train, and y_test\n",
    "if X_train is not None and y_train is not None:\n",
    "    print(\"\\nShapes of the split datasets:\")\n",
    "    print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "    print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20eadcc1-3a42-4852-945c-a8db1c6c9d87",
   "metadata": {},
   "source": [
    "## 4.2 Explanation:\n",
    "\n",
    "1. **Imports**: We import necessary libraries including pandas (`import pandas as pd`) for data handling and `train_test_split` from `sklearn.model_selection` for splitting the dataset.\n",
    "\n",
    "2. **split_dataset Function**:\n",
    "   - **Purpose**: This function splits the Hogwarts students dataset into training and testing sets.\n",
    "   - **Parameters**: \n",
    "     - `file_path` (str): Path to the CSV file containing the dataset.\n",
    "     - `test_size` (float): Proportion of the dataset to include in the test split (default is 0.2).\n",
    "     - `random_state` (int): Controls the shuffling applied to the data before applying the split (default is 42).\n",
    "   - **Returns**: `X_train` (DataFrame), `X_test` (DataFrame), `y_train` (Series), `y_test` (Series) - Training and testing sets for features (`X_train`, `X_test`) and target (`y_train`, `y_test`).\n",
    "\n",
    "3. **Error Handling**: The function includes error handling to manage scenarios where the file is not found (`FileNotFoundError`) or any other unexpected errors (`Exception`).\n",
    "\n",
    "4. **Data Splitting**:\n",
    "   - Loads the dataset into a pandas DataFrame (`df`) from the specified `file_path`.\n",
    "   - Displays basic information about the dataset, including its dimensions.\n",
    "   - Uses `train_test_split` to split the dataset into training (`X_train`, `y_train`) and testing (`X_test`, `y_test`) sets, based on the specified `test_size` and `random_state`.\n",
    "   - Prints the shapes of the resulting training and testing sets for verification.\n",
    "\n",
    "5. **Main Execution**:\n",
    "   - Defines `file_path` as `\"data/hogwarts-students.csv\"`, assuming the dataset is located in a subfolder named `data`.\n",
    "   - Calls `split_dataset(file_path)` to split the dataset into training and testing sets, assigning the returned values (`X_train`, `X_test`, `y_train`, `y_test`) to variables for further use.\n",
    "\n",
    "6. **Example Usage**:\n",
    "   - Demonstrates accessing and displaying the shapes of `X_train`, `X_test`, `y_train`, and `y_test` after the dataset splitting process.\n",
    "\n",
    "### Notes:\n",
    "- Ensure the `pandas` and `scikit-learn` libraries are installed (`pip install pandas scikit-learn`) before running the script.\n",
    "- Adjust `file_path`, `test_size`, and `random_state` parameters as needed based on specific requirements.\n",
    "- This script provides a foundational approach to splitting data into training and testing sets, essential for building and evaluating machine learning models on the Hogwarts students dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ea3959-7c2d-45e2-80fe-03e07d7ff38f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba97030-8c57-4b98-86e1-6a5309c5dab8",
   "metadata": {},
   "source": [
    "# 5. Casting the Decision Tree Spell (Building the Model)\n",
    "\n",
    "In the enchanted heart of Hogwarts, where the very walls seem to hum with ancient magic, we now embark on the most exciting part of our journey: casting the Decision Tree spell. This spell, much like a Patronus, will illuminate the path, predicting the rightful house for each new witch and wizard. ü™Ñ‚ú®\n",
    "\n",
    "**Choosing the Algorithm**: Our journey begins in the mystical realm of algorithms, where we select the Decision Tree, a spell as wise as Dumbledore and as precise as Professor McGonagall. The Decision Tree algorithm is a magical construct that makes decisions based on the attributes of our witches and wizards, much like the Sorting Hat itself. üé©üåü\n",
    "\n",
    "**Training the Model**: Picture our algorithm as a young student, eager to learn. We feed it the Training Set, a collection of 80% of our dataset, filled with the known traits and house assignments of various characters. This step is akin to studying Hogwarts: A History before exams‚Äîevery detail, every pattern is crucial.\n",
    "\n",
    "- **Learning the Patterns**: The algorithm examines each character‚Äôs attributes‚Äîage, origin, specialty, and more‚Äîlearning how these features align with their house. It‚Äôs a bit like the Sorting Hat delving into the minds of first-years, sensing bravery, cunning, intelligence, and loyalty. üß†‚ú®\n",
    "- **Creating the Tree**: As it learns, the algorithm constructs a Decision Tree. At each node of the tree, it asks a question based on the attributes (e.g., \"Is this character's specialty Potions?\"). Depending on the answer, it follows a branch to the next node, asking another question, until it reaches a leaf node that predicts the house. This tree, with its branches and leaves, grows much like the Whomping Willow‚Äîcomplex and precise. üå≥üîÆ\n",
    "\n",
    "**Visualizing the Tree**: Imagine, if you will, a grand tapestry unfurling, each thread representing a decision, each knot a question answered. This visualization helps us see the wisdom within our algorithm, much like the Marauder‚Äôs Map revealing the secrets of Hogwarts. üó∫Ô∏è‚ú®\n",
    "\n",
    "**Fine-Tuning the Spell**: Just as Hermione would refine her spells for maximum effectiveness, we can adjust the parameters of our Decision Tree. We might change the depth of the tree or the criteria for splitting nodes, ensuring our model is as sharp as Godric Gryffindor‚Äôs sword. üó°Ô∏èüîß\n",
    "\n",
    "**Avoiding Overfitting**: One must be wary, however, of the dangers of overfitting‚Äîa spell that is too tailored to the Training Set might falter when faced with new data. It‚Äôs like a wizard relying too heavily on a single spell without mastering others. To prevent this, we employ techniques to prune the tree, ensuring it remains general enough to handle new students. üåø‚ú®\n",
    "\n",
    "With our model trained and fine-tuned, it stands ready, a powerful artifact of Muggle ingenuity and magical wonder. The Decision Tree, much like the enchanted Sorting Hat, is now prepared to predict the house of any witch or wizard with remarkable accuracy.\n",
    "\n",
    "As we stand at the cusp of discovery, the echoes of Hogwarts‚Äô rich history surround us. The magic is palpable, the excitement tangible, and the possibilities endless. The Decision Tree spell is cast, and with it, we step into a new era of magical prediction, blending the charm of the wizarding world with the precision of Muggle science. ü™Ñüåüüßô‚Äç‚ôÇÔ∏èüßô‚Äç‚ôÄÔ∏è\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac8eb3b-04e4-4a2f-8816-14efb32a8708",
   "metadata": {},
   "source": [
    "## 5.1 Python Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "70851686-bb42-4e36-b37e-52d7c651e289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Decision Tree model: 0.27\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      1.00         1\n",
      "           1       1.00      0.00      0.00         1\n",
      "           2       0.50      0.50      0.50         2\n",
      "           3       0.25      1.00      0.40         1\n",
      "           4       0.00      0.00      1.00         2\n",
      "           5       1.00      0.25      0.40         4\n",
      "\n",
      "    accuracy                           0.27        11\n",
      "   macro avg       0.46      0.29      0.55        11\n",
      "weighted avg       0.57      0.27      0.55        11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "def load_data(file_path):\n",
    "    \"\"\"\n",
    "    Function to load and preprocess the Hogwarts students dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    - file_path (str): Path to the CSV file containing the dataset.\n",
    "    \n",
    "    Returns:\n",
    "    - df (DataFrame): Preprocessed pandas DataFrame containing the dataset.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the dataset into a pandas DataFrame\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Handling missing values\n",
    "        imputer = SimpleImputer(strategy='most_frequent')  # Impute with most frequent value\n",
    "        df_filled = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "        \n",
    "        # Encoding categorical variables\n",
    "        label_encoder = LabelEncoder()\n",
    "        df_encoded = df_filled.copy()\n",
    "        for col in df.select_dtypes(include=['object']).columns:\n",
    "            df_encoded[col] = label_encoder.fit_transform(df_filled[col])\n",
    "        \n",
    "        return df_encoded\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{file_path}' was not found.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error: An unexpected error occurred - {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def build_decision_tree_model(file_path):\n",
    "    \"\"\"\n",
    "    Function to build a Decision Tree model on the Hogwarts students dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    - file_path (str): Path to the CSV file containing the dataset.\n",
    "    \n",
    "    Returns:\n",
    "    - clf (DecisionTreeClassifier): Trained Decision Tree classifier model.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load and preprocess the dataset\n",
    "        df = load_data(file_path)\n",
    "        if df is None:\n",
    "            return None\n",
    "        \n",
    "        # Split the dataset into training and testing sets\n",
    "        X = df.drop('house', axis=1)  # Features (excluding the target 'house')\n",
    "        y = df['house']  # Target variable ('house')\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        \n",
    "        # Build the Decision Tree model\n",
    "        clf = DecisionTreeClassifier(random_state=42)\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions on the test set\n",
    "        y_pred = clf.predict(X_test)\n",
    "        \n",
    "        # Evaluate the model\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(f\"Accuracy of the Decision Tree model: {accuracy:.2f}\")\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(classification_report(y_test, y_pred, zero_division=1))  # Set zero_division to 1\n",
    "        \n",
    "        return clf\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error: An unexpected error occurred - {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Path to the dataset file\n",
    "file_path = \"data/hogwarts-students.csv\"\n",
    "\n",
    "# Call the build_decision_tree_model function to build and evaluate the Decision Tree model\n",
    "decision_tree_model = build_decision_tree_model(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f252f3b9-1cf1-4e07-ae23-a1310f4bd418",
   "metadata": {},
   "source": [
    "## 5.2 Explanation:\n",
    "\n",
    "1. **Imports**: We import necessary libraries including pandas (`import pandas as pd`), `DecisionTreeClassifier` from `sklearn.tree`, `accuracy_score` and `classification_report` from `sklearn.metrics`, `train_test_split` from `sklearn.model_selection`, `LabelEncoder` from `sklearn.preprocessing`, and `SimpleImputer` from `sklearn.impute`.\n",
    "\n",
    "2. **load_data Function**:\n",
    "   - **Purpose**: This function loads and preprocesses the Hogwarts students dataset, handling missing values and encoding categorical variables.\n",
    "   - **Parameters**: `file_path` (str) - Path to the CSV file containing the dataset.\n",
    "   - **Returns**: `df` (DataFrame) - Preprocessed pandas DataFrame containing the dataset.\n",
    "\n",
    "3. **build_decision_tree_model Function**:\n",
    "   - **Purpose**: This function builds a Decision Tree model on the Hogwarts students dataset, evaluates its performance, and prints the accuracy and classification report.\n",
    "   - **Parameters**: `file_path` (str) - Path to the CSV file containing the dataset.\n",
    "   - **Returns**: `clf` (DecisionTreeClassifier) - Trained Decision Tree classifier model.\n",
    "\n",
    "4. **Error Handling**: Both functions include error handling to manage scenarios where the file is not found (`FileNotFoundError`) or any other unexpected errors (`Exception`).\n",
    "\n",
    "5. **Data Loading and Preprocessing**:\n",
    "   - **In `load_data` function**: Loads the dataset into a pandas DataFrame (`df`), fills missing values using `SimpleImputer`, and encodes categorical variables using `LabelEncoder`.\n",
    "   - **In `build_decision_tree_model` function**: Calls `load_data(file_path)` to preprocess the dataset, splits it into training (`X_train`, `y_train`) and testing (`X_test`, `y_test`) sets using `train_test_split`.\n",
    "\n",
    "6. **Building the Decision Tree Model**:\n",
    "   - Initializes a `DecisionTreeClassifier` with a fixed `random_state`.\n",
    "   - Trains the classifier (`clf`) on the training data (`X_train`, `y_train`).\n",
    "\n",
    "7. **Model Evaluation**:\n",
    "   - Makes predictions (`y_pred`) on the test set (`X_test`).\n",
    "   - Computes and prints the accuracy score and classification report to evaluate the model's performance.\n",
    "\n",
    "8. **Main Execution**:\n",
    "   - Defines `file_path` as `\"data/hogwarts-students.csv\"`, assuming the dataset is located in a subfolder named `data`.\n",
    "   - Calls `build_decision_tree_model(file_path)` to build and evaluate the Decision Tree model, assigning the returned trained model (`decision_tree_model`) for further use.\n",
    "\n",
    "### Notes:\n",
    "\n",
    "- Ensure the `pandas` and `scikit-learn` libraries are installed (`pip install pandas scikit-learn`) before running the script.\n",
    "- Adjust `file_path` parameter if the dataset file is located in a different directory.\n",
    "- This script provides a foundational approach to building and evaluating a Decision Tree model on the Hogwarts students dataset, demonstrating steps from data preprocessing to model training and evaluation. Adjustments can be made based on specific requirements or additional preprocessing steps needed for the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbb2fdd-5907-4dd0-b8ef-dda6d8d9ff03",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44d2537-875e-466c-8425-0b7404f0b676",
   "metadata": {},
   "source": [
    "# 6. Testing the Spell (Evaluating the Model)\n",
    "\n",
    "As the first light of dawn casts a golden glow over the turrets of Hogwarts, we stand ready to test our Decision Tree spell. The air is thick with anticipation, much like the moments before a Quidditch match, where every second counts and the stakes are high. üè∞‚ú®\n",
    "\n",
    "**Making Predictions**: Our model, now trained and refined, is poised to reveal its magic. We present it with the Testing Set, the 20% of our dataset it has never seen before. This is its true test, akin to a young witch or wizard facing their O.W.L.s. The algorithm, like the Sorting Hat placed on a new student's head, will predict the house for each character based on their attributes. üé©üîÆ\n",
    "\n",
    "**Comparing Predictions to Actual Houses**: As the predictions unfurl, we compare them to the actual house assignments, much like comparing a prophecy from Sybill Trelawney to the events it foretold. Each correct prediction brings a thrill of validation, a testament to the spell‚Äôs accuracy. üßô‚Äç‚ôÇÔ∏èüìú\n",
    "\n",
    "**Accuracy and Metrics**: To measure our spell‚Äôs potency, we turn to a set of magical metrics:\n",
    "\n",
    "- **Accuracy**: The proportion of correctly predicted houses to the total predictions. This gives us a sense of the spell‚Äôs overall effectiveness, much like a well-brewed potion.\n",
    "- **Precision**: For each house, we calculate how many of the characters predicted to be in that house truly belong there. It‚Äôs as if we‚Äôre assessing the accuracy of Professor Snape‚Äôs potion ingredients.\n",
    "- **Recall**: This metric reveals how well our model identifies all the characters of a particular house. Imagine it as Madam Pomfrey ensuring she hasn‚Äôt missed any detail in her healing spells.\n",
    "- **F1 Score**: A harmonic mean of precision and recall, providing a balanced measure of our model‚Äôs performance. Think of it as balancing the scales in a wizard‚Äôs duel, ensuring fairness and accuracy. ‚öñÔ∏è‚ú®\n",
    "\n",
    "**Confusion Matrix**: To further delve into our spell‚Äôs performance, we use a confusion matrix. This grid, much like the Marauder‚Äôs Map, reveals where our predictions have strayed. Each cell tells a story‚Äîtrue positives, false positives, and false negatives‚Äîoffering insights into where our spell might need refinement. üó∫Ô∏èüìä\n",
    "\n",
    "**Visualizing the Results**: Just as Harry might consult the Pensieve to review memories, we use visualizations to understand our model‚Äôs performance. Graphs and charts, akin to enchanted diagrams in a spellbook, illuminate our spell‚Äôs strengths and weaknesses, guiding us in our next steps. üìà‚ú®\n",
    "\n",
    "**Reflecting on the Spell‚Äôs Performance**: As we evaluate the results, we reflect on our model‚Äôs journey, much like reflecting on a year‚Äôs worth of adventures at Hogwarts. Each success, each misstep, offers a lesson, a path to greater accuracy. We consider adjustments, perhaps pruning the tree further or adding new features, ensuring our spell grows stronger with each iteration.\n",
    "\n",
    "With the Testing Set evaluated, we stand at the threshold of a new understanding. Our Decision Tree spell, born from the marriage of Muggle science and magical wonder, has shown its prowess. The Sorting Hat‚Äôs wisdom, mirrored in our model, shines brightly, ready to guide future generations of witches and wizards to their rightful houses. üåüüßô‚Äç‚ôÄÔ∏èüè∞\n",
    "\n",
    "The journey has been as thrilling as a ride on a Nimbus 2000, filled with discovery, learning, and magic. And so, with our spell tested and our hearts full of pride, we look forward to the future, where the enchantment of Hogwarts continues to blend seamlessly with the ingenuity of Muggle technology. ü™Ñ‚ú®\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f95d96-16e2-4f29-b066-2cc917210d8a",
   "metadata": {},
   "source": [
    "## 6.1 Python Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "abda663d-92dd-4f60-8765-2aebafa0673f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Decision Tree model: 0.27\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      1.00         1\n",
      "           1       1.00      0.00      0.00         1\n",
      "           2       0.50      0.50      0.50         2\n",
      "           3       0.25      1.00      0.40         1\n",
      "           4       0.00      0.00      1.00         2\n",
      "           5       1.00      0.25      0.40         4\n",
      "\n",
      "    accuracy                           0.27        11\n",
      "   macro avg       0.46      0.29      0.55        11\n",
      "weighted avg       0.57      0.27      0.55        11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "def load_and_preprocess_data(file_path):\n",
    "    \"\"\"\n",
    "    Function to load and preprocess the Hogwarts students dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    - file_path (str): Path to the CSV file containing the dataset.\n",
    "    \n",
    "    Returns:\n",
    "    - df (DataFrame): Preprocessed pandas DataFrame containing the dataset.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the dataset into a pandas DataFrame\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Handle missing values\n",
    "        imputer = SimpleImputer(strategy='most_frequent')  # Impute with most frequent value\n",
    "        df_filled = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "        \n",
    "        # Encode categorical variables\n",
    "        label_encoder = LabelEncoder()\n",
    "        df_encoded = df_filled.copy()\n",
    "        for col in df.select_dtypes(include=['object']).columns:\n",
    "            df_encoded[col] = label_encoder.fit_transform(df_filled[col])\n",
    "        \n",
    "        return df_encoded\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{file_path}' was not found.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error: An unexpected error occurred - {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def build_and_evaluate_decision_tree_model(file_path):\n",
    "    \"\"\"\n",
    "    Function to build and evaluate a Decision Tree model on the Hogwarts students dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    - file_path (str): Path to the CSV file containing the dataset.\n",
    "    \n",
    "    Returns:\n",
    "    - clf (DecisionTreeClassifier): Trained Decision Tree classifier model.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load and preprocess the dataset\n",
    "        df = load_and_preprocess_data(file_path)\n",
    "        if df is None:\n",
    "            return None\n",
    "        \n",
    "        # Split the dataset into training and testing sets\n",
    "        X = df.drop('house', axis=1)  # Features (excluding the target 'house')\n",
    "        y = df['house']  # Target variable ('house')\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        \n",
    "        # Initialize the Decision Tree classifier\n",
    "        clf = DecisionTreeClassifier(random_state=42)\n",
    "        \n",
    "        # Train the classifier\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions on the test set\n",
    "        y_pred = clf.predict(X_test)\n",
    "        \n",
    "        # Evaluate the model's performance\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(f\"Accuracy of the Decision Tree model: {accuracy:.2f}\")\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(classification_report(y_test, y_pred, zero_division=1))  # Set zero_division to 1\n",
    "        \n",
    "        return clf\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error: An unexpected error occurred - {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Path to the dataset file\n",
    "file_path = \"data/hogwarts-students.csv\"\n",
    "\n",
    "# Build and evaluate the Decision Tree model\n",
    "decision_tree_model = build_and_evaluate_decision_tree_model(file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c466e6b2-3322-4c69-b99a-d1187061118f",
   "metadata": {},
   "source": [
    "## 6.2 Explanation:\n",
    "\n",
    "1. **Imports**:\n",
    "   - `pandas` for data manipulation.\n",
    "   - `DecisionTreeClassifier` for building the decision tree model.\n",
    "   - `accuracy_score` and `classification_report` for evaluating the model.\n",
    "   - `train_test_split` for splitting the dataset into training and testing sets.\n",
    "   - `LabelEncoder` for encoding categorical variables.\n",
    "   - `SimpleImputer` for handling missing values.\n",
    "\n",
    "2. **load_and_preprocess_data Function**:\n",
    "   - **Purpose**: Loads and preprocesses the Hogwarts students dataset.\n",
    "   - **Steps**:\n",
    "     - Loads the dataset into a pandas DataFrame.\n",
    "     - Handles missing values using `SimpleImputer` with the most frequent value strategy.\n",
    "     - Encodes categorical variables using `LabelEncoder`.\n",
    "   - **Returns**: Preprocessed DataFrame.\n",
    "\n",
    "3. **build_and_evaluate_decision_tree_model Function**:\n",
    "   - **Purpose**: Builds and evaluates a Decision Tree model on the Hogwarts students dataset.\n",
    "   - **Steps**:\n",
    "     - Calls `load_and_preprocess_data` to load and preprocess the dataset.\n",
    "     - Splits the dataset into features (`X`) and target (`y`), and then into training and testing sets using `train_test_split`.\n",
    "     - Initializes a `DecisionTreeClassifier`.\n",
    "     - Trains the classifier on the training data.\n",
    "     - Makes predictions on the test data.\n",
    "     - Evaluates the model‚Äôs performance by calculating the accuracy and printing a classification report with `zero_division` set to 1 to handle any undefined metrics.\n",
    "   - **Returns**: Trained `DecisionTreeClassifier` model.\n",
    "\n",
    "4. **Main Execution**:\n",
    "   - Defines the `file_path` as \"data/hogwarts-students.csv\".\n",
    "   - Calls `build_and_evaluate_decision_tree_model(file_path)` to build and evaluate the Decision Tree model, storing the trained model in `decision_tree_model`.\n",
    "\n",
    "### Notes:\n",
    "- Ensure the `pandas` and `scikit-learn` libraries are installed (`pip install pandas scikit-learn`) before running the script.\n",
    "- Adjust the `file_path` parameter if the dataset file is located in a different directory.\n",
    "- This script provides a clear and structured approach to building and evaluating a Decision Tree model, making it easy to follow and adapt for further use or additional preprocessing steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089bd054-4883-46e7-82d8-a0e750995121",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd94742-ae67-4797-9f1d-5e792dcb8883",
   "metadata": {},
   "source": [
    "# 7. Fine-Tuning the Spell (Improving the Model)\n",
    "\n",
    "As the sun sets over the Forbidden Forest and the first stars twinkle above the spires of Hogwarts, we embark on the delicate task of fine-tuning our Decision Tree spell. This process, as intricate as crafting a new wand, requires both skill and patience. Our goal is to perfect our model, ensuring it performs with the grace and precision of a well-cast Patronus. üå≥‚ú®\n",
    "\n",
    "**Reviewing the Results**: Much like Professor Dumbledore reflecting on the events of the past year, we begin by reviewing the performance of our model. The accuracy, precision, recall, and F1 scores give us a glimpse into its strengths and weaknesses. We consult our confusion matrix, which, like a magical map, reveals where our predictions went awry. üó∫Ô∏èüìä\n",
    "\n",
    "**Identifying Areas for Improvement**: Our analysis reveals certain patterns‚Äîperhaps our model struggles with certain houses or misclassifies characters with specific attributes. These insights are as enlightening as discovering a hidden room in Hogwarts, guiding us toward potential improvements. üîç‚ú®\n",
    "\n",
    "**Pruning the Tree**: One of the first steps in fine-tuning is pruning our Decision Tree. By reducing its complexity, we prevent it from overfitting to the Training Set, ensuring it generalizes better to new data. This process is akin to Professor Sprout trimming the Whomping Willow, keeping it healthy and manageable. üå≥‚úÇÔ∏è\n",
    "\n",
    "**Adjusting Parameters**: Next, we delve into the parameters that guide our model. We might adjust the maximum depth of the tree, the minimum samples required to split a node, or the minimum samples required at a leaf node. Each tweak is like adjusting the settings on a magical artifact, fine-tuning it for optimal performance. üõ†Ô∏èüîÆ\n",
    "\n",
    "**Feature Engineering**: Sometimes, the key to a better model lies in the features themselves. We might create new features that capture deeper insights into our characters, such as combining age and favorite class to better understand academic inclinations. This step is as creative as inventing new spells, blending knowledge and imagination. ‚ú®üìö\n",
    "\n",
    "**Cross-Validation**: To ensure our improvements are effective, we employ cross-validation, a technique that divides our Training Set into multiple folds, training and testing the model on each. This process, much like practicing a spell under different conditions, ensures our model is robust and reliable. üßô‚Äç‚ôÄÔ∏èüìú\n",
    "\n",
    "**Hyperparameter Tuning**: For the most meticulous fine-tuning, we explore hyperparameter tuning, using methods like Grid Search or Random Search to find the best combination of parameters. This step is as detailed as brewing a complex potion, where each ingredient must be measured to perfection. üß™‚ú®\n",
    "\n",
    "**Ensemble Methods**: To further enhance our model‚Äôs accuracy, we might employ ensemble methods, combining the predictions of multiple Decision Trees. Techniques like Random Forest or Gradient Boosting can create a more powerful and accurate model, much like the combined efforts of the Hogwarts professors in times of crisis. üåüüå≥üå≥üå≥\n",
    "\n",
    "**Evaluating the Improved Model**: With our spell fine-tuned, we once again evaluate its performance using the Testing Set. The results, we hope, will show marked improvement, much like the transformation of Neville Longbottom from a timid first-year to a courageous hero. ü¶Å‚ú®\n",
    "\n",
    "**Reflecting on the Journey**: As we complete this stage, we reflect on the journey we‚Äôve undertaken. From gathering the data to casting and fine-tuning our spell, each step has been a blend of magical wonder and Muggle ingenuity. Our model, now more accurate and robust, stands ready to predict the houses of Hogwarts with newfound confidence. üåüüè∞\n",
    "\n",
    "And so, dear reader, with our spell refined and our hearts full of pride, we look forward to the future. The enchantment of Hogwarts and the precision of machine learning have combined to create something truly magical. Let us continue to explore, learn, and grow, for the world of magic holds endless possibilities. ü™Ñ‚ú®üßô‚Äç‚ôÇÔ∏èüßô‚Äç‚ôÄÔ∏è\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "53cbc5b9-a35f-4176-b63c-bedaaf4fe675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Decision Tree model: 0.64\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67         1\n",
      "           2       1.00      0.25      0.40         4\n",
      "           3       0.50      1.00      0.67         1\n",
      "           4       1.00      1.00      1.00         2\n",
      "           5       0.50      0.67      0.57         3\n",
      "\n",
      "    accuracy                           0.64        11\n",
      "   macro avg       0.70      0.78      0.66        11\n",
      "weighted avg       0.77      0.64      0.60        11\n",
      "\n",
      "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/DATA/Python/pythonenv/lib/python3.8/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0sAccuracy of the fine-tuned Decision Tree model: 0.55\n",
      "\n",
      "Classification Report (fine-tuned model):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67         1\n",
      "           1       0.00      1.00      0.00         0\n",
      "           2       1.00      0.25      0.40         4\n",
      "           3       0.50      1.00      0.67         1\n",
      "           4       1.00      1.00      1.00         2\n",
      "           5       0.50      0.33      0.40         3\n",
      "\n",
      "    accuracy                           0.55        11\n",
      "   macro avg       0.58      0.76      0.52        11\n",
      "weighted avg       0.77      0.55      0.56        11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "def load_and_preprocess_data(file_path):\n",
    "    \"\"\"\n",
    "    Function to load and preprocess the Hogwarts students dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    - file_path (str): Path to the CSV file containing the dataset.\n",
    "    \n",
    "    Returns:\n",
    "    - df (DataFrame): Preprocessed pandas DataFrame containing the dataset.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the dataset into a pandas DataFrame\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Handle missing values\n",
    "        imputer = SimpleImputer(strategy='most_frequent')  # Impute with most frequent value\n",
    "        df_filled = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "        \n",
    "        # Encode categorical variables\n",
    "        label_encoder = LabelEncoder()\n",
    "        df_encoded = df_filled.copy()\n",
    "        for col in df.select_dtypes(include=['object']).columns:\n",
    "            df_encoded[col] = label_encoder.fit_transform(df_filled[col])\n",
    "        \n",
    "        return df_encoded\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{file_path}' was not found.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error: An unexpected error occurred - {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def build_and_evaluate_decision_tree_model(file_path):\n",
    "    \"\"\"\n",
    "    Function to build and evaluate a Decision Tree model on the Hogwarts students dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    - file_path (str): Path to the CSV file containing the dataset.\n",
    "    \n",
    "    Returns:\n",
    "    - clf (DecisionTreeClassifier): Trained Decision Tree classifier model.\n",
    "    - X_train, X_test, y_train, y_test (arrays): Training and testing sets.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load and preprocess the dataset\n",
    "        df = load_and_preprocess_data(file_path)\n",
    "        if df is None:\n",
    "            return None, None, None, None, None\n",
    "        \n",
    "        # Split the dataset into training and testing sets using stratified split\n",
    "        X = df.drop('house', axis=1)  # Features (excluding the target 'house')\n",
    "        y = df['house']  # Target variable ('house')\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "        \n",
    "        # Initialize the Decision Tree classifier\n",
    "        clf = DecisionTreeClassifier(random_state=42)\n",
    "        \n",
    "        # Train the classifier\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions on the test set\n",
    "        y_pred = clf.predict(X_test)\n",
    "        \n",
    "        # Evaluate the model's performance\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(f\"Accuracy of the Decision Tree model: {accuracy:.2f}\")\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(classification_report(y_test, y_pred, zero_division=1))  # Set zero_division to 1\n",
    "        \n",
    "        return clf, X_train, X_test, y_train, y_test\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error: An unexpected error occurred - {str(e)}\")\n",
    "        return None, None, None, None, None\n",
    "\n",
    "def fine_tune_decision_tree_model(file_path):\n",
    "    \"\"\"\n",
    "    Function to fine-tune the Decision Tree model using GridSearchCV.\n",
    "    \n",
    "    Parameters:\n",
    "    - file_path (str): Path to the CSV file containing the dataset.\n",
    "    \n",
    "    Returns:\n",
    "    - best_clf (DecisionTreeClassifier): Best Decision Tree classifier model after fine-tuning.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Build and evaluate the initial Decision Tree model\n",
    "        clf, X_train, X_test, y_train, y_test = build_and_evaluate_decision_tree_model(file_path)\n",
    "        if clf is None:\n",
    "            return None\n",
    "        \n",
    "        # Define the parameter grid for hyperparameter tuning\n",
    "        param_grid = {\n",
    "            'criterion': ['gini', 'entropy'],\n",
    "            'splitter': ['best', 'random'],\n",
    "            'max_depth': [None, 10, 20, 30],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'min_samples_leaf': [1, 2, 4]\n",
    "        }\n",
    "        \n",
    "        # Initialize GridSearchCV with the Decision Tree classifier\n",
    "        # Use StratifiedKFold with n_splits=3 to handle the case with very few samples in some classes\n",
    "        skf = StratifiedKFold(n_splits=3)\n",
    "        grid_search = GridSearchCV(estimator=clf, param_grid=param_grid, cv=skf, n_jobs=-1, verbose=2)\n",
    "        \n",
    "        # Perform the grid search to find the best parameters\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        \n",
    "        # Get the best estimator (Decision Tree model with the best parameters)\n",
    "        best_clf = grid_search.best_estimator_\n",
    "        \n",
    "        # Make predictions on the test set using the best model\n",
    "        y_pred_best = best_clf.predict(X_test)\n",
    "        \n",
    "        # Evaluate the best model's performance\n",
    "        accuracy_best = accuracy_score(y_test, y_pred_best)\n",
    "        print(f\"Accuracy of the fine-tuned Decision Tree model: {accuracy_best:.2f}\")\n",
    "        print(\"\\nClassification Report (fine-tuned model):\")\n",
    "        print(classification_report(y_test, y_pred_best, zero_division=1))  # Set zero_division to 1\n",
    "        \n",
    "        return best_clf\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error: An unexpected error occurred - {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Path to the dataset file\n",
    "file_path = \"data/hogwarts-students.csv\"\n",
    "\n",
    "# Fine-tune the Decision Tree model\n",
    "fine_tuned_model = fine_tune_decision_tree_model(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57dc6249-12a3-4d6c-a899-d024f230881d",
   "metadata": {},
   "source": [
    "# 8. Applying the Spell (Using the Model)\n",
    "\n",
    "As the golden rays of dawn pierce through the ancient windows of Hogwarts, casting ethereal patterns on the stone floors, we reach the moment we've all been eagerly anticipating: applying our Decision Tree spell. The halls buzz with excitement, much like the anticipation before a new term feast. It's time to put our magical creation to use and witness the Sorting Hat's wisdom in a new, innovative form. üè∞‚ú®\n",
    "\n",
    "**Gathering New Students**: Imagine the Great Hall filled with first-years, their eyes wide with wonder and hearts pounding with anticipation. Our task is to predict the houses for these new witches and wizards, each bringing their unique traits and potential. Just as Professor McGonagall calls each name, our model will analyze each student's attributes‚Äîage, origin, specialty, and more‚Äîto determine their rightful house. üìúüåü\n",
    "\n",
    "**Loading the Model**: We start by summoning our meticulously crafted model, stored safely in the digital equivalent of a Gringotts vault. With a few incantations (or lines of code, for the Muggles among us), we bring our model to life, ready to cast its predictive magic. üßô‚Äç‚ôÇÔ∏èüîÆ\n",
    "\n",
    "**Making Predictions**: As each new student steps forward, we feed their attributes into our model. The algorithm, like the Sorting Hat, delves into the depths of their data, evaluating each feature with precision. The result is a prediction, as clear and confident as the Hat‚Äôs pronouncement of \"Gryffindor!\" or \"Ravenclaw!\" üé©‚ú®\n",
    "\n",
    "- **Example**: Consider a young witch named Elara Moonshadow, with a specialty in Charms, a love for Herbology, and a background from a small wizarding village. Our model examines her traits, traversing the branches of the Decision Tree, and finally, it declares, \"Hufflepuff!\" The excitement in Elara's eyes mirrors the pride we feel in our model‚Äôs accuracy. üåüüßô‚Äç‚ôÄÔ∏è\n",
    "\n",
    "**Real-Time Feedback**: As each prediction is made, we compare it with the known assignments (if available) or await feedback from the students themselves. This step is as dynamic and interactive as a Defense Against the Dark Arts class with Professor Lupin, where each spell cast is immediately evaluated. üõ°Ô∏è‚ú®\n",
    "\n",
    "**Handling Uncertainty**: Occasionally, our model might hesitate, much like the Sorting Hat‚Äôs famous deliberation over Harry Potter. In such cases, we can explore additional features or even employ ensemble methods to ensure our prediction is as accurate as possible. This adaptability is akin to consulting the wisdom of multiple professors to reach a consensus. üßô‚Äç‚ôÇÔ∏èüßô‚Äç‚ôÄÔ∏èüåü\n",
    "\n",
    "**Continuous Learning**: Our model, much like the magical creatures in Hagrid‚Äôs care, continues to learn and evolve. With each new prediction, we gather more data, refining and enhancing the model‚Äôs accuracy. This ongoing learning process ensures that our spell remains as sharp as ever, ready to sort future generations with increasing precision. üìö‚ú®\n",
    "\n",
    "**Integration into Hogwarts Life**: Imagine a future where our model is seamlessly integrated into Hogwarts‚Äô magical tapestry. From assisting the Sorting Hat during the Welcoming Feast to providing insights into students‚Äô strengths and potential, the possibilities are endless. This fusion of magic and technology heralds a new era in Hogwarts history, one where tradition and innovation coexist harmoniously. üåüüè∞\n",
    "\n",
    "As we stand back and marvel at the application of our Decision Tree spell, we feel a profound sense of accomplishment. The journey from data gathering to model deployment has been as enchanting as a journey through the Forbidden Forest, filled with discovery and wonder. With our model in place, the future of sorting at Hogwarts shines brighter than ever. ü™Ñ‚ú®\n",
    "\n",
    "And so, dear reader, with hearts full of joy and minds brimming with knowledge, we look forward to the adventures that lie ahead. The magic of Hogwarts, intertwined with the ingenuity of machine learning, promises a future as bright and boundless as the skies over the castle. üååüßô‚Äç‚ôÇÔ∏èüßô‚Äç‚ôÄÔ∏è\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7249f6e4-cd64-4ac3-bef4-6b84361059fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/DATA/Python/pythonenv/lib/python3.8/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=50, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=1, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=2, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=50, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.0sError: An unexpected error occurred - y contains previously unseen labels: 'New Wizard'\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def load_and_preprocess_data(file_path):\n",
    "    \"\"\"\n",
    "    Function to load and preprocess the Hogwarts students dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    - file_path (str): Path to the CSV file containing the dataset.\n",
    "    \n",
    "    Returns:\n",
    "    - df (DataFrame): Preprocessed pandas DataFrame containing the dataset.\n",
    "    - feature_names (list): List of feature names used for training.\n",
    "    - label_encoders (dict): Dictionary of label encoders for each categorical feature.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the dataset into a pandas DataFrame\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Handle missing values\n",
    "        imputer = SimpleImputer(strategy='most_frequent')  # Impute with most frequent value\n",
    "        df_filled = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "        \n",
    "        # Encode categorical variables\n",
    "        label_encoders = {}\n",
    "        df_encoded = df_filled.copy()\n",
    "        for col in df.select_dtypes(include=['object']).columns:\n",
    "            label_encoders[col] = LabelEncoder()\n",
    "            df_encoded[col] = label_encoders[col].fit_transform(df_filled[col])\n",
    "        \n",
    "        feature_names = df_encoded.columns.tolist()\n",
    "        feature_names.remove('house')  # Exclude the target variable from features\n",
    "        \n",
    "        return df_encoded, feature_names, label_encoders\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{file_path}' was not found.\")\n",
    "        return None, None, None\n",
    "    except Exception as e:\n",
    "        print(f\"Error: An unexpected error occurred - {str(e)}\")\n",
    "        return None, None, None\n",
    "\n",
    "def fine_tune_decision_tree_model(file_path):\n",
    "    \"\"\"\n",
    "    Function to fine-tune the Decision Tree model using GridSearchCV.\n",
    "    \n",
    "    Parameters:\n",
    "    - file_path (str): Path to the CSV file containing the dataset.\n",
    "    \n",
    "    Returns:\n",
    "    - best_clf (DecisionTreeClassifier): Best Decision Tree classifier model after fine-tuning.\n",
    "    - feature_names (list): List of feature names used for training.\n",
    "    - label_encoders (dict): Dictionary of label encoders for each categorical feature.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load and preprocess the dataset\n",
    "        df, feature_names, label_encoders = load_and_preprocess_data(file_path)\n",
    "        if df is None:\n",
    "            return None, None, None\n",
    "        \n",
    "        # Split the dataset into features and target\n",
    "        X = df[feature_names]  # Features (excluding the target 'house')\n",
    "        y = df['house']  # Target variable ('house')\n",
    "        \n",
    "        # Initialize the Decision Tree classifier\n",
    "        clf = DecisionTreeClassifier(random_state=42)\n",
    "        \n",
    "        # Define the parameter grid for hyperparameter tuning\n",
    "        param_grid = {\n",
    "            'criterion': ['gini', 'entropy'],\n",
    "            'splitter': ['best', 'random'],\n",
    "            'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'min_samples_leaf': [1, 2, 4]\n",
    "        }\n",
    "        \n",
    "        # Initialize GridSearchCV with the Decision Tree classifier\n",
    "        grid_search = GridSearchCV(estimator=clf, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "        \n",
    "        # Perform the grid search to find the best parameters\n",
    "        grid_search.fit(X, y)\n",
    "        \n",
    "        # Get the best estimator (Decision Tree model with the best parameters)\n",
    "        best_clf = grid_search.best_estimator_\n",
    "        \n",
    "        return best_clf, feature_names, label_encoders\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error: An unexpected error occurred - {str(e)}\")\n",
    "        return None, None, None\n",
    "\n",
    "def apply_model(model, feature_names, label_encoders, new_data):\n",
    "    \"\"\"\n",
    "    Function to apply the trained Decision Tree model to new data.\n",
    "    \n",
    "    Parameters:\n",
    "    - model (DecisionTreeClassifier): Trained Decision Tree model.\n",
    "    - feature_names (list): List of feature names used for training.\n",
    "    - label_encoders (dict): Dictionary of label encoders for each categorical feature.\n",
    "    - new_data (DataFrame): New data for which predictions are to be made.\n",
    "    \n",
    "    Returns:\n",
    "    - predictions (array): Predicted houses for the new data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Encode new data using the same encoders as the training data\n",
    "        for col in label_encoders:\n",
    "            if col in new_data.columns:\n",
    "                new_data[col] = label_encoders[col].transform(new_data[col])\n",
    "            else:\n",
    "                new_data[col] = 0  # Adding missing features with default value\n",
    "        \n",
    "        # Ensure new data has the same columns as the training data\n",
    "        for feature in feature_names:\n",
    "            if feature not in new_data.columns:\n",
    "                new_data[feature] = 0  # Adding missing features with default value\n",
    "        \n",
    "        # Align new data with feature names\n",
    "        new_data = new_data[feature_names]\n",
    "        \n",
    "        # Make predictions using the trained model\n",
    "        predictions = model.predict(new_data)\n",
    "        \n",
    "        return predictions\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error: An unexpected error occurred - {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Path to the dataset file\n",
    "file_path = \"data/hogwarts-students.csv\"\n",
    "\n",
    "# Fine-tune the Decision Tree model\n",
    "fine_tuned_model, feature_names, label_encoders = fine_tune_decision_tree_model(file_path)\n",
    "\n",
    "# Example new data (you can replace this with actual new data)\n",
    "new_data = pd.DataFrame({\n",
    "    'name': ['New Wizard'],\n",
    "    'gender': ['Male'],\n",
    "    'age': [12],\n",
    "    'origin': ['Muggle-born'],\n",
    "    'specialty': ['Defense Against the Dark Arts'],\n",
    "    'wand_type': ['Phoenix Feather'],\n",
    "    'patronus': ['Stag'],\n",
    "    'broomstick': ['Firebolt'],\n",
    "    'favourite_subject': ['Charms'],\n",
    "    'quidditch_position': ['Seeker']\n",
    "})\n",
    "\n",
    "# Apply the model to the new data\n",
    "if fine_tuned_model and feature_names and label_encoders:\n",
    "    predictions = apply_model(fine_tuned_model, feature_names, label_encoders, new_data)\n",
    "    if predictions is not None:\n",
    "        print(\"Predicted House for the new wizard:\", predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2564bec9-9ea7-4d2f-a817-0579a61bf36d",
   "metadata": {},
   "source": [
    "## 9. Conclusion\n",
    "\n",
    "As the last light of day fades over the sprawling grounds of Hogwarts, the castle stands as a beacon of timeless magic and boundless discovery. In these hallowed halls, where every stone whispers tales of ancient wisdom and every corridor hums with the promise of adventure, we conclude our remarkable journey through the art of magical prediction. üè∞‚ú®\n",
    "\n",
    "**Reflecting on Our Journey**: Our expedition began with a simple yet profound question: could we, using the marvels of Muggle science, create a model to emulate the Sorting Hat‚Äôs centuries-old wisdom? Like young Harry, Ron, and Hermione setting out to unravel the mysteries of the Philosopher‚Äôs Stone, we embarked with curiosity and determination. And oh, what a journey it has been! üöÇ‚ú®\n",
    "\n",
    "**From Data Gathering to Spell Casting**: We meticulously gathered data, much like Professor Binns compiling the chronicles of wizarding history. Each character‚Äôs attributes, from their age and origin to their favorite subjects and magical abilities, were carefully documented. With these magical ingredients in hand, we crafted our Decision Tree spell, a wondrous blend of Muggle technology and wizarding intuition. üìúüîÆ\n",
    "\n",
    "- **The Training Phase**: Our model learned from the rich tapestry of data, discerning patterns and making connections. It was akin to Hermione mastering complex spells through relentless study and practice. üìö‚ú®\n",
    "- **Testing and Evaluation**: We tested our spell with the rigour of a Triwizard Tournament challenge, ensuring its accuracy and reliability. Each prediction, each metric, was a step towards perfection, reminiscent of Harry honing his skills for the final confrontation with Voldemort. üêâ‚ö°\n",
    "- **Fine-Tuning and Application**: Through fine-tuning, we enhanced our model‚Äôs prowess, preparing it to face real-world sorting scenarios. And when the moment arrived, our model performed with the grace and precision of a perfectly executed Patronus charm. üåüü™Ñ\n",
    "\n",
    "**A New Dawn at Hogwarts**: The integration of our Decision Tree model into the sorting process represents a new dawn at Hogwarts. It is a testament to the harmony between tradition and innovation, a bridge between the timeless magic of the wizarding world and the cutting-edge advancements of the Muggle realm. The Sorting Hat, ever wise and ever patient, welcomes this partnership, embracing the future with open arms. üé©‚ú®\n",
    "\n",
    "**The Promise of Future Adventures**: As we stand on the threshold of this new era, we are filled with a sense of wonder and anticipation. The lessons we‚Äôve learned, the spells we‚Äôve cast, and the predictions we‚Äôve made are but the beginning. The world of magic is vast, and the possibilities are endless. With our newfound knowledge, who knows what other mysteries we might unravel, what other spells we might cast? The future beckons, bright and full of promise. üååüßô‚Äç‚ôÇÔ∏èüßô‚Äç‚ôÄÔ∏è\n",
    "\n",
    "And so, dear reader, as the stars twinkle above and the gentle hum of magic fills the air, we close this chapter of our adventure. But remember, at Hogwarts, every ending is but a new beginning. The magic of the castle, the wisdom of its inhabitants, and the spirit of discovery live on, ever ready to guide us on our next great journey.\n",
    "\n",
    "Until then, keep the magic alive in your heart, and may your days be filled with wonder and enchantment. üåüüè∞‚ú®"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a52b162-5ed4-4820-80a7-74abcb8e774f",
   "metadata": {},
   "source": [
    "# The End\n",
    "\n",
    "Or perhaps, just the beginning... ü™Ñüåüüßô‚Äç‚ôÇÔ∏èüßô‚Äç‚ôÄÔ∏è\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "\"Python/Mu (mu_venv-38-20221007-072305)\"",
   "language": "python",
   "name": "mu_venv-38-20221007-072305"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
